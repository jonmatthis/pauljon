{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0ffe42",
   "metadata": {},
   "source": [
    "# WebResearchRetriever\n",
    "\n",
    "Given a query, this retriever will: \n",
    "\n",
    "* Formulate a set of relate Google searches\n",
    "* Search for each \n",
    "* Load all the resulting URLs\n",
    "* Then embed and perform similarity search with the query on the consolidate page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b79e2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"Checking dependencies...\")\n",
    "# %pip install --upgrade pip --quiet\n",
    "# %pip install langchain --quiet\n",
    "# %pip install python-dotenv --quiet\n",
    "# %pip install openai --quiet\n",
    "# %pip install beautifulsoup4 --quiet\n",
    "# %pip install chromadb --quiet\n",
    "%pip install google-api-python-client --quiet\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13548212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T23:19:00.079999Z",
     "start_time": "2023-10-25T23:18:55.551734Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1dcbd",
   "metadata": {},
   "source": [
    "### Simple usage\n",
    "\n",
    "Specify the LLM to use for Google search query generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63d1c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T23:20:43.511528Z",
     "start_time": "2023-10-25T23:20:43.496242Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "# Vectorstore\n",
    "vectorstore = Chroma(embedding_function=OpenAIEmbeddings(),persist_directory=\"./chroma_db_oai\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Search \n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"xxx\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"xxx\"\n",
    "search = GoogleSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118b50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm, \n",
    "    search=search, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39114da4",
   "metadata": {},
   "source": [
    "#### Run with citations\n",
    "\n",
    "We can use `RetrievalQAWithSourcesChain` to retrieve docs and provide citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b330acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 400 when requesting https://customsearch.googleapis.com/customsearch/v1?q=1.+What+is+the+functioning+principle+of+LLM+Powered+Autonomous+Agents%3F&cx=xxx&num=1&key=xxx&alt=json returned \"API key not valid. Please pass a valid API key.\". Details: \"[{'message': 'API key not valid. Please pass a valid API key.', 'domain': 'global', 'reason': 'badRequest'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHttpError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m/Users/jon/github_repos/jonmatthis/pauljon/web_research.ipynb Cell 8\u001B[0m line \u001B[0;36m4\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/pauljon/web_research.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001B[0m user_input \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mHow do LLM Powered Autonomous Agents work?\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/pauljon/web_research.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001B[0m qa_chain \u001B[39m=\u001B[39m RetrievalQAWithSourcesChain\u001B[39m.\u001B[39mfrom_chain_type(llm,retriever\u001B[39m=\u001B[39mweb_research_retriever)\n\u001B[0;32m----> <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/pauljon/web_research.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001B[0m result \u001B[39m=\u001B[39m qa_chain({\u001B[39m\"\u001B[39;49m\u001B[39mquestion\u001B[39;49m\u001B[39m\"\u001B[39;49m: user_input})\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/pauljon/web_research.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001B[0m result\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/chains/base.py:310\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mBaseException\u001B[39;00m \u001B[39mas\u001B[39;00m e:\n\u001B[1;32m    309\u001B[0m     run_manager\u001B[39m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 310\u001B[0m     \u001B[39mraise\u001B[39;00m e\n\u001B[1;32m    311\u001B[0m run_manager\u001B[39m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    312\u001B[0m final_outputs: Dict[\u001B[39mstr\u001B[39m, Any] \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mprep_outputs(\n\u001B[1;32m    313\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    314\u001B[0m )\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/chains/base.py:304\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[1;32m    297\u001B[0m run_manager \u001B[39m=\u001B[39m callback_manager\u001B[39m.\u001B[39mon_chain_start(\n\u001B[1;32m    298\u001B[0m     dumpd(\u001B[39mself\u001B[39m),\n\u001B[1;32m    299\u001B[0m     inputs,\n\u001B[1;32m    300\u001B[0m     name\u001B[39m=\u001B[39mrun_name,\n\u001B[1;32m    301\u001B[0m )\n\u001B[1;32m    302\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m    303\u001B[0m     outputs \u001B[39m=\u001B[39m (\n\u001B[0;32m--> 304\u001B[0m         \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_call(inputs, run_manager\u001B[39m=\u001B[39;49mrun_manager)\n\u001B[1;32m    305\u001B[0m         \u001B[39mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    306\u001B[0m         \u001B[39melse\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_call(inputs)\n\u001B[1;32m    307\u001B[0m     )\n\u001B[1;32m    308\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mBaseException\u001B[39;00m \u001B[39mas\u001B[39;00m e:\n\u001B[1;32m    309\u001B[0m     run_manager\u001B[39m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/chains/qa_with_sources/base.py:151\u001B[0m, in \u001B[0;36mBaseQAWithSourcesChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    147\u001B[0m accepts_run_manager \u001B[39m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m     \u001B[39m\"\u001B[39m\u001B[39mrun_manager\u001B[39m\u001B[39m\"\u001B[39m \u001B[39min\u001B[39;00m inspect\u001B[39m.\u001B[39msignature(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_get_docs)\u001B[39m.\u001B[39mparameters\n\u001B[1;32m    149\u001B[0m )\n\u001B[1;32m    150\u001B[0m \u001B[39mif\u001B[39;00m accepts_run_manager:\n\u001B[0;32m--> 151\u001B[0m     docs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_get_docs(inputs, run_manager\u001B[39m=\u001B[39;49m_run_manager)\n\u001B[1;32m    152\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     docs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_get_docs(inputs)  \u001B[39m# type: ignore[call-arg]\u001B[39;00m\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/chains/qa_with_sources/retrieval.py:50\u001B[0m, in \u001B[0;36mRetrievalQAWithSourcesChain._get_docs\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_get_docs\u001B[39m(\n\u001B[1;32m     47\u001B[0m     \u001B[39mself\u001B[39m, inputs: Dict[\u001B[39mstr\u001B[39m, Any], \u001B[39m*\u001B[39m, run_manager: CallbackManagerForChainRun\n\u001B[1;32m     48\u001B[0m ) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m List[Document]:\n\u001B[1;32m     49\u001B[0m     question \u001B[39m=\u001B[39m inputs[\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mquestion_key]\n\u001B[0;32m---> 50\u001B[0m     docs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mretriever\u001B[39m.\u001B[39;49mget_relevant_documents(\n\u001B[1;32m     51\u001B[0m         question, callbacks\u001B[39m=\u001B[39;49mrun_manager\u001B[39m.\u001B[39;49mget_child()\n\u001B[1;32m     52\u001B[0m     )\n\u001B[1;32m     53\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_reduce_tokens_below_limit(docs)\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/schema/retriever.py:211\u001B[0m, in \u001B[0;36mBaseRetriever.get_relevant_documents\u001B[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mException\u001B[39;00m \u001B[39mas\u001B[39;00m e:\n\u001B[1;32m    210\u001B[0m     run_manager\u001B[39m.\u001B[39mon_retriever_error(e)\n\u001B[0;32m--> 211\u001B[0m     \u001B[39mraise\u001B[39;00m e\n\u001B[1;32m    212\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    213\u001B[0m     run_manager\u001B[39m.\u001B[39mon_retriever_end(\n\u001B[1;32m    214\u001B[0m         result,\n\u001B[1;32m    215\u001B[0m         \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs,\n\u001B[1;32m    216\u001B[0m     )\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/schema/retriever.py:204\u001B[0m, in \u001B[0;36mBaseRetriever.get_relevant_documents\u001B[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m _kwargs \u001B[39m=\u001B[39m kwargs \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_expects_other_args \u001B[39melse\u001B[39;00m {}\n\u001B[1;32m    203\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_new_arg_supported:\n\u001B[0;32m--> 204\u001B[0m     result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_get_relevant_documents(\n\u001B[1;32m    205\u001B[0m         query, run_manager\u001B[39m=\u001B[39;49mrun_manager, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49m_kwargs\n\u001B[1;32m    206\u001B[0m     )\n\u001B[1;32m    207\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_get_relevant_documents(query, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39m_kwargs)\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/retrievers/web_research.py:185\u001B[0m, in \u001B[0;36mWebResearchRetriever._get_relevant_documents\u001B[0;34m(self, query, run_manager)\u001B[0m\n\u001B[1;32m    182\u001B[0m urls_to_look \u001B[39m=\u001B[39m []\n\u001B[1;32m    183\u001B[0m \u001B[39mfor\u001B[39;00m query \u001B[39min\u001B[39;00m questions:\n\u001B[1;32m    184\u001B[0m     \u001B[39m# Google search\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     search_results \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msearch_tool(query, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mnum_search_results)\n\u001B[1;32m    186\u001B[0m     logger\u001B[39m.\u001B[39minfo(\u001B[39m\"\u001B[39m\u001B[39mSearching for relevant urls...\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m    187\u001B[0m     logger\u001B[39m.\u001B[39minfo(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mSearch results: \u001B[39m\u001B[39m{\u001B[39;00msearch_results\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/retrievers/web_research.py:155\u001B[0m, in \u001B[0;36mWebResearchRetriever.search_tool\u001B[0;34m(self, query, num_search_results)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[39m\u001B[39m\u001B[39m\"\"\"Returns num_search_results pages per Google search.\"\"\"\u001B[39;00m\n\u001B[1;32m    154\u001B[0m query_clean \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mclean_search_query(query)\n\u001B[0;32m--> 155\u001B[0m result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msearch\u001B[39m.\u001B[39;49mresults(query_clean, num_search_results)\n\u001B[1;32m    156\u001B[0m \u001B[39mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/utilities/google_search.py:123\u001B[0m, in \u001B[0;36mGoogleSearchAPIWrapper.results\u001B[0;34m(self, query, num_results, search_params)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[39m\u001B[39m\u001B[39m\"\"\"Run query through GoogleSearch and return metadata.\u001B[39;00m\n\u001B[1;32m    110\u001B[0m \n\u001B[1;32m    111\u001B[0m \u001B[39mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[39m        link - The link to the result.\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m    122\u001B[0m metadata_results \u001B[39m=\u001B[39m []\n\u001B[0;32m--> 123\u001B[0m results \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_google_search_results(\n\u001B[1;32m    124\u001B[0m     query, num\u001B[39m=\u001B[39;49mnum_results, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49m(search_params \u001B[39mor\u001B[39;49;00m {})\n\u001B[1;32m    125\u001B[0m )\n\u001B[1;32m    126\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(results) \u001B[39m==\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[1;32m    127\u001B[0m     \u001B[39mreturn\u001B[39;00m [{\u001B[39m\"\u001B[39m\u001B[39mResult\u001B[39m\u001B[39m\"\u001B[39m: \u001B[39m\"\u001B[39m\u001B[39mNo good Google Search Result was found\u001B[39m\u001B[39m\"\u001B[39m}]\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/langchain/utilities/google_search.py:62\u001B[0m, in \u001B[0;36mGoogleSearchAPIWrapper._google_search_results\u001B[0;34m(self, search_term, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39msiterestrict:\n\u001B[1;32m     61\u001B[0m     cse \u001B[39m=\u001B[39m cse\u001B[39m.\u001B[39msiterestrict()\n\u001B[0;32m---> 62\u001B[0m res \u001B[39m=\u001B[39m cse\u001B[39m.\u001B[39;49mlist(q\u001B[39m=\u001B[39;49msearch_term, cx\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mgoogle_cse_id, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\u001B[39m.\u001B[39;49mexecute()\n\u001B[1;32m     63\u001B[0m \u001B[39mreturn\u001B[39;00m res\u001B[39m.\u001B[39mget(\u001B[39m\"\u001B[39m\u001B[39mitems\u001B[39m\u001B[39m\"\u001B[39m, [])\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001B[0m, in \u001B[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m     \u001B[39melif\u001B[39;00m positional_parameters_enforcement \u001B[39m==\u001B[39m POSITIONAL_WARNING:\n\u001B[1;32m    129\u001B[0m         logger\u001B[39m.\u001B[39mwarning(message)\n\u001B[0;32m--> 130\u001B[0m \u001B[39mreturn\u001B[39;00m wrapped(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m~/github_repos/jonmatthis/pauljon/venv/lib/python3.11/site-packages/googleapiclient/http.py:938\u001B[0m, in \u001B[0;36mHttpRequest.execute\u001B[0;34m(self, http, num_retries)\u001B[0m\n\u001B[1;32m    936\u001B[0m     callback(resp)\n\u001B[1;32m    937\u001B[0m \u001B[39mif\u001B[39;00m resp\u001B[39m.\u001B[39mstatus \u001B[39m>\u001B[39m\u001B[39m=\u001B[39m \u001B[39m300\u001B[39m:\n\u001B[0;32m--> 938\u001B[0m     \u001B[39mraise\u001B[39;00m HttpError(resp, content, uri\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39muri)\n\u001B[1;32m    939\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpostproc(resp, content)\n",
      "\u001B[0;31mHttpError\u001B[0m: <HttpError 400 when requesting https://customsearch.googleapis.com/customsearch/v1?q=1.+What+is+the+functioning+principle+of+LLM+Powered+Autonomous+Agents%3F&cx=xxx&num=1&key=xxx&alt=json returned \"API key not valid. Please pass a valid API key.\". Details: \"[{'message': 'API key not valid. Please pass a valid API key.', 'domain': 'global', 'reason': 'badRequest'}]\">"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "user_input = \"How do LLM Powered Autonomous Agents work?\"\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm,retriever=web_research_retriever)\n",
    "result = qa_chain({\"question\": user_input})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357559fd",
   "metadata": {},
   "source": [
    "#### Run with logging\n",
    "\n",
    "Here, we use `get_relevant_documents` method to return docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.web_research\").setLevel(logging.INFO)\n",
    "user_input = \"What is Task Decomposition in LLM Powered Autonomous Agents?\"\n",
    "docs = web_research_retriever.get_relevant_documents(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681a846",
   "metadata": {},
   "source": [
    "#### Generate answer using retrieved docs\n",
    "\n",
    "We can use `load_qa_chain` for QA using the retrieved docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "output = chain({\"input_documents\": docs, \"question\": user_input},return_only_outputs=True)\n",
    "output['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e57bb",
   "metadata": {},
   "source": [
    "### More flexibility\n",
    "\n",
    "Pass an LLM chain with custom prompt and output parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
    "\n",
    "# LLMChain\n",
    "search_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an assistant tasked with improving Google search \n",
    "    results. Generate FIVE Google search queries that are similar to\n",
    "    this question. The output should be a numbered list of questions and each\n",
    "    should have a question mark at the end: {question}\"\"\",\n",
    ")\n",
    "\n",
    "class LineList(BaseModel):\n",
    "    \"\"\"List of questions.\"\"\"\n",
    "\n",
    "    lines: List[str] = Field(description=\"Questions\")\n",
    "\n",
    "class QuestionListOutputParser(PydanticOutputParser):\n",
    "    \"\"\"Output parser for a list of numbered questions.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = re.findall(r\"\\d+\\..*?\\n\", text)\n",
    "        return LineList(lines=lines)\n",
    "    \n",
    "llm_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=search_prompt,\n",
    "            output_parser=QuestionListOutputParser(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b0471",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "web_research_retriever_llm_chain = WebResearchRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    llm_chain=llm_chain, \n",
    "    search=search, \n",
    ")\n",
    "\n",
    "# Run\n",
    "docs = web_research_retriever_llm_chain.get_relevant_documents(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee52163",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9530c0",
   "metadata": {},
   "source": [
    "### Run locally\n",
    "\n",
    "Specify LLM and embeddings that will run locally (e.g., on your laptop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llama = LlamaCpp(\n",
    "    model_path=\"/Users/rlm/Desktop/Code/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=4096,  # Context window\n",
    "    max_tokens=1000,  # Max tokens to generate\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f93dd4",
   "metadata": {},
   "source": [
    "We supplied `StreamingStdOutCallbackHandler()`, so model outputs (e.g., generated questions) are streamed. \n",
    "\n",
    "We also have logging on, so we seem them there too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0561ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore_llama,\n",
    "    llm=llama, \n",
    "    search=search, \n",
    ")\n",
    "\n",
    "# Run\n",
    "user_input = \"What is Task Decomposition in LLM Powered Autonomous Agents?\"\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llama,retriever=web_research_retriever)\n",
    "result = qa_chain({\"question\": user_input})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
