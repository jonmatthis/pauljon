{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0ffe42",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# WebResearchRetriever\n",
    "\n",
    "Given a query, this retriever will: \n",
    "\n",
    "* Formulate a set of relate Google searches\n",
    "* Search for each \n",
    "* Load all the resulting URLs\n",
    "* Then embed and perform similarity search with the query on the consolidate page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b79e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Checking dependencies...\")\n",
    "# %pip install --upgrade pip --quiet\n",
    "# %pip install langchain --quiet\n",
    "# %pip install python-dotenv --quiet\n",
    "# %pip install openai --quiet\n",
    "# %pip install beautifulsoup4 --quiet\n",
    "# %pip install chromadb --quiet\n",
    "# %pip install google-api-python-client --quiet\n",
    "# %pip install html2text --quiet\n",
    "# %pip install tiktoken --quiet\n",
    "# %pip install rich --quiet\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# notebook.output.wordWrap = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13548212",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1dcbd",
   "metadata": {},
   "source": [
    "### Simple usage\n",
    "\n",
    "Specify the LLM to use for Google search query generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "# Vectorstore\n",
    "vectorstore = Chroma(embedding_function=OpenAIEmbeddings(),persist_directory=\"./chroma_db_oai\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "load_dotenv()\n",
    "# Search \n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "search = GoogleSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm, \n",
    "    search=search, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39114da4",
   "metadata": {},
   "source": [
    "#### Run with citations\n",
    "\n",
    "We can use `RetrievalQAWithSourcesChain` to retrieve docs and provide citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b330acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.web_research:Generating questions for Google Search ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {'question': 'What is FreeMoCap?', 'text': LineList(lines=['1. What does FreeMoCap stand for?\\n', '2. How does FreeMoCap work?\\n', '3. Can you explain the concept of FreeMoCap?'])}\n",
      "INFO:langchain.retrievers.web_research:Questions for Google Search: ['1. What does FreeMoCap stand for?\\n', '2. How does FreeMoCap work?\\n', '3. Can you explain the concept of FreeMoCap?']\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'title': 'Home | The FreeMoCap Project', 'link': 'https://freemocap.org/', 'snippet': 'The Free Motion Capture Project (FreeMoCap) aims to provide research-grade markerless motion capture software to everyone for free.'}]\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'title': 'freemocap/freemocap: Free Motion Capture for Everyone - GitHub', 'link': 'https://github.com/freemocap/freemocap', 'snippet': 'Mar 14, 2023 ... This project is licensed under the APGL License - see the LICENSE file for details. If the AGPL does not work for your needs, we are happy\\xa0...'}]\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'title': 'FreeMoCap Rough Cut Tutorial/Walkthrough/Brain Dump (Nov 2022 ...', 'link': 'https://www.youtube.com/watch?v=GxKmyKdnTy0', 'snippet': \"Nov 3, 2022 ... NOTE - This is a work in progress kinda thing! This video was recorded in Nov 2022, if you're watching it significantly after that, it is\\xa0...\"}]\n",
      "INFO:langchain.retrievers.web_research:New URLs to load: ['https://freemocap.org/', 'https://www.youtube.com/watch?v=GxKmyKdnTy0', 'https://github.com/freemocap/freemocap']\n",
      "INFO:langchain.retrievers.web_research:Indexing new urls...\n",
      "Fetching pages: 100%|##########| 3/3 [00:00<00:00,  5.62it/s]\n",
      "INFO:langchain.retrievers.web_research:Grabbing most relevant splits from urls...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FreeMoCap is a free and open-source motion capture system and platform. It is designed to be hardware and software agnostic, meaning it can work with different types of motion capture devices and software. FreeMoCap aims to provide a minimal-cost solution for motion capture, making it accessible for scientific research, education, and training purposes. It offers a graphical user interface (GUI) and supports decentralized scientific research.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "user_input = \"What is FreeMoCap?\"\n",
    "\n",
    "\n",
    "# qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm,retriever=web_research_retriever)\n",
    "docs = web_research_retriever.get_relevant_documents(user_input)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "output = chain({\"input_documents\": docs, \"question\": user_input},return_only_outputs=True)\n",
    "output['output_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"question\": user_input})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357559fd",
   "metadata": {},
   "source": [
    "#### Run with logging\n",
    "\n",
    "Here, we use `get_relevant_documents` method to return docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.web_research\").setLevel(logging.INFO)\n",
    "user_input = \"Who is Yocheved Lifshitz?\"\n",
    "docs = web_research_retriever.get_relevant_documents(user_input)\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "output = chain({\"input_documents\": docs, \"question\": user_input},return_only_outputs=True)\n",
    "output['output_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681a846",
   "metadata": {},
   "source": [
    "#### Generate answer using retrieved docs\n",
    "\n",
    "We can use `load_qa_chain` for QA using the retrieved docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bbc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c0e57bb",
   "metadata": {},
   "source": [
    "### More flexibility\n",
    "\n",
    "Pass an LLM chain with custom prompt and output parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
    "\n",
    "# LLMChain\n",
    "search_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an assistant tasked with improving Google search \n",
    "    results. Generate FIVE Google search queries that are similar to\n",
    "    this question. The output should be a numbered list of questions and each\n",
    "    should have a question mark at the end: {question}\"\"\",\n",
    ")\n",
    "\n",
    "class LineList(BaseModel):\n",
    "    \"\"\"List of questions.\"\"\"\n",
    "\n",
    "    lines: List[str] = Field(description=\"Questions\")\n",
    "\n",
    "class QuestionListOutputParser(PydanticOutputParser):\n",
    "    \"\"\"Output parser for a list of numbered questions.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = re.findall(r\"\\d+\\..*?\\n\", text)\n",
    "        return LineList(lines=lines)\n",
    "    \n",
    "llm_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=search_prompt,\n",
    "            output_parser=QuestionListOutputParser(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b0471",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "web_research_retriever_llm_chain = WebResearchRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    llm_chain=llm_chain, \n",
    "    search=search, \n",
    ")\n",
    "\n",
    "# Run\n",
    "docs = web_research_retriever_llm_chain.get_relevant_documents(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee52163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rich import print\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9530c0",
   "metadata": {},
   "source": [
    "### Run locally\n",
    "\n",
    "Specify LLM and embeddings that will run locally (e.g., on your laptop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import LlamaCpp\n",
    "# from langchain.embeddings import GPT4AllEmbeddings\n",
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "# n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# llama = LlamaCpp(\n",
    "#     model_path=\"/Users/rlm/Desktop/Code/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\",\n",
    "#     n_gpu_layers=n_gpu_layers,\n",
    "#     n_batch=n_batch,\n",
    "#     n_ctx=4096,  # Context window\n",
    "#     max_tokens=1000,  # Max tokens to generate\n",
    "#     f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "#     callback_manager=callback_manager,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f93dd4",
   "metadata": {},
   "source": [
    "We supplied `StreamingStdOutCallbackHandler()`, so model outputs (e.g., generated questions) are streamed. \n",
    "\n",
    "We also have logging on, so we seem them there too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0561ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm, \n",
    "    search=search, \n",
    ")\n",
    "\n",
    "# Run\n",
    "user_input = \"What is Task Decomposition in LLM Powered Autonomous Agents?\"\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm,retriever=web_research_retriever)\n",
    "result = qa_chain({\"question\": user_input})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0251ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
